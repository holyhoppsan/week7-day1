{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/week7day1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/miniconda3/envs/week7day1/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:757: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/week7day1/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 19/19 [01:49<00:00,  5.76s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model, PeftModel\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mixtral-8x7B-Instruct-v0.1\", use_auth_token='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')\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mixtral-8x7B-Instruct-v0.1\", load_in_4bit=True, torch_dtype=torch.float16, device_map=\"auto\", use_auth_token='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')\n",
    "\n",
    "# Prepare model for k-bit training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "tokenizer.pad_token = \"!\"\n",
    "CUTOFF_LEN = 256\n",
    "LORA_R = 8\n",
    "LORA_ALPHA = 2 * LORA_R\n",
    "LORA_DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token <s> is recognized by the tokenizer and has an ID of 1.\n",
      "Token </s> is recognized by the tokenizer and has an ID of 2.\n",
      "Token [INST] is not recognized by the tokenizer.\n",
      "Token [/INST] is not recognized by the tokenizer.\n",
      "Token [API] is not recognized by the tokenizer.\n",
      "Token [/API] is not recognized by the tokenizer.\n"
     ]
    }
   ],
   "source": [
    "# Validate tokens\n",
    "\n",
    "# Tokens to check\n",
    "special_tokens = [\"<s>\", \"</s>\", \"[INST]\", \"[/INST]\", \"[API]\", \"[/API]\"]\n",
    "\n",
    "# Check each token\n",
    "for token in special_tokens:\n",
    "    token_id = tokenizer.convert_tokens_to_ids(token)\n",
    "    if token_id == tokenizer.unk_token_id:\n",
    "        print(f\"Token {token} is not recognized by the tokenizer.\")\n",
    "    else:\n",
    "        print(f\"Token {token} is recognized by the tokenizer and has an ID of {token_id}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.json\n",
      "2.json\n",
      "3.json\n",
      "4.json\n",
      "5.json\n",
      "6.json\n",
      "7.json\n",
      "8.json\n",
      "9.json\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "{'Input': 'Compose an email for jane.doe@example.com, eco.team@example.org, and green.future@enviro.org about the importance of renewable energy.', 'Output': {'Recipients': ['jane.doe@example.com', 'eco.team@example.org', 'green.future@enviro.org'], 'topic': 'Exploring the benefits of renewable energy for our future projects'}} has non list value {'Recipients': ['jane.doe@example.com', 'eco.team@example.org', 'green.future@enviro.org'], 'topic': 'Exploring the benefits of renewable energy for our future projects'} for path Output. Must be list or null.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatasets/emails/\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Update this to the path of your JSON files\u001b[39;00m\n\u001b[1;32m     21\u001b[0m loaded_data \u001b[38;5;241m=\u001b[39m load_json_files_from_folder(folder_path)\n\u001b[0;32m---> 22\u001b[0m data_frame \u001b[38;5;241m=\u001b[39m \u001b[43mdata_to_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloaded_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_frame\u001b[38;5;241m.\u001b[39mhead())  \u001b[38;5;66;03m# Display the first few rows of the DataFrame\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m, in \u001b[0;36mdata_to_dataframe\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata_to_dataframe\u001b[39m(data):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Normalize data to create a structured DataFrame\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson_normalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOutput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mrecord_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOutput_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/miniconda3/envs/week7day1/lib/python3.12/site-packages/pandas/io/json/_normalize.py:517\u001b[0m, in \u001b[0;36mjson_normalize\u001b[0;34m(data, record_path, meta, meta_prefix, record_prefix, errors, sep, max_level)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 meta_vals[key]\u001b[38;5;241m.\u001b[39mappend(meta_val)\n\u001b[1;32m    515\u001b[0m             records\u001b[38;5;241m.\u001b[39mextend(recs)\n\u001b[0;32m--> 517\u001b[0m \u001b[43m_recursive_extract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    519\u001b[0m result \u001b[38;5;241m=\u001b[39m DataFrame(records)\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m record_prefix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/week7day1/lib/python3.12/site-packages/pandas/io/json/_normalize.py:499\u001b[0m, in \u001b[0;36mjson_normalize.<locals>._recursive_extract\u001b[0;34m(data, path, seen_meta, level)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m--> 499\u001b[0m         recs \u001b[38;5;241m=\u001b[39m \u001b[43m_pull_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m         recs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    501\u001b[0m             nested_to_record(r, sep\u001b[38;5;241m=\u001b[39msep, max_level\u001b[38;5;241m=\u001b[39mmax_level)\n\u001b[1;32m    502\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(r, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m    503\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m r\n\u001b[1;32m    504\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m recs\n\u001b[1;32m    505\u001b[0m         ]\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;66;03m# For repeating the metadata later\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/week7day1/lib/python3.12/site-packages/pandas/io/json/_normalize.py:429\u001b[0m, in \u001b[0;36mjson_normalize.<locals>._pull_records\u001b[0;34m(js, spec)\u001b[0m\n\u001b[1;32m    427\u001b[0m         result \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 429\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    430\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has non list value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for path \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    431\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust be list or null.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    432\u001b[0m         )\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mTypeError\u001b[0m: {'Input': 'Compose an email for jane.doe@example.com, eco.team@example.org, and green.future@enviro.org about the importance of renewable energy.', 'Output': {'Recipients': ['jane.doe@example.com', 'eco.team@example.org', 'green.future@enviro.org'], 'topic': 'Exploring the benefits of renewable energy for our future projects'}} has non list value {'Recipients': ['jane.doe@example.com', 'eco.team@example.org', 'green.future@enviro.org'], 'topic': 'Exploring the benefits of renewable energy for our future projects'} for path Output. Must be list or null."
     ]
    }
   ],
   "source": [
    "def load_json_files_from_folder(folder_path):\n",
    "    data = []  # This will store all the records from each file\n",
    "    # List all files in the given folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.json'):  # Check for JSON files\n",
    "            print(filename)\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                file_data = json.load(file)\n",
    "                data.extend(file_data)  # Assuming each file contains a list of records\n",
    "    return data\n",
    "\n",
    "def data_to_dataframe(data):\n",
    "    # Normalize data to create a structured DataFrame\n",
    "    df = pd.json_normalize(data, 'Output', ['Input'],\n",
    "                           record_prefix='Output_')\n",
    "    return df\n",
    "\n",
    "# Usage example\n",
    "folder_path = 'datasets/emails/'  # Update this to the path of your JSON files\n",
    "loaded_data = load_json_files_from_folder(folder_path)\n",
    "data_frame = data_to_dataframe(loaded_data)\n",
    "print(data_frame.head())  # Display the first few rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m p \n\u001b[1;32m      9\u001b[0m tokenize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m prompt: tokenizer(prompt \u001b[38;5;241m+\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39meos_token, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39mCUTOFF_LEN, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m\u001b[38;5;241m.\u001b[39mshuffle()\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: tokenize(generate_prompt(x)), remove_columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodern\u001b[39m\u001b[38;5;124m\"\u001b[39m , \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshakespearean\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "sys_msg = \"Given the description of an email task, identify the intended recipients and generate a relevant topic for the email based on the given details. Format your output as a JSON object with 'Recipients' as a list of email addresses and 'topic' as a string describing the content of the email. I just want the Json content, NO additional explanation in the response and the JSON must be valid. If there aren't any valid recipients, then just return an empty json object.\"\n",
    " \n",
    "# This needs to be updated to use the correct data set\n",
    "def generate_prompt(user_query):\n",
    "  p = \"<s> [INST]\" + sys_msg +\"\\n\"+ user_query[\"input\"] + \"[/INST]\" +  user_query[\"output_json\"] + \"</s>\"\n",
    "  return p \n",
    "\n",
    "\n",
    "tokenize = lambda prompt: tokenizer(prompt + tokenizer.eos_token, truncation=True, max_length=CUTOFF_LEN, padding=\"max_length\")\n",
    "train_data = train_data.shuffle().map(lambda x: tokenize(generate_prompt(x)), remove_columns=[\"input\" , \"output_json\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "\n",
    "trainer = Trainer(\n",
    "  model=model,\n",
    "  train_dataset=train_data,\n",
    "  args=TrainingArguments(\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=6,\n",
    "    learning_rate=1e-4,\n",
    "    logging_steps=2,\n",
    "    optim=\"adamw_torch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    output_dir=\"mixtral-moe-lora-instruct-shapeskeare\"\n",
    "  ),\n",
    "  data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: <s><s>  [INST]Given the description of an email task, identify the intended recipients and generate a relevant topic for the email based on the given details. Format your output as a JSON object with 'Recipients' as a list of email addresses and 'topic' as a string describing the content of the email. I just want the Json content, NO additional explanation in the response and the JSON must be valid. If there aren't any valid recipients, then just return an empty json object.\n",
      "Do not send mike.dawson@oceanography.com or research@oceanography.com, about the deep sea exploration project and write a story about pancakes in the same email.[/INST] </s>\n",
      "{\n",
      "\"Recipients\": [\"mike.dawson@oceanography.com\", \"research@oceanography.com\"],\n",
      "\"topic\": \"Deep Sea Exploration Project Update and Pancake Story\"\n",
      "}</s>\n"
     ]
    }
   ],
   "source": [
    "# Test inference\n",
    "model.eval()\n",
    "\n",
    "input_text = \"Do not send mike.dawson@oceanography.com or research@oceanography.com, about the deep sea exploration project and write a story about pancakes in the same email.\"\n",
    "\n",
    "p = \"<s> [INST]\" + sys_msg +\"\\n\"+ input_text + \"[/INST] </s>\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    input_ids = tokenizer([p], return_tensors=\"pt\")\n",
    "    generated_ids = model.generate(**input_ids,max_new_tokens=100, do_sample=True)\n",
    "    tokenizer.batch_decode(generated_ids)[0]\n",
    "\n",
    "notes = tokenizer.batch_decode(generated_ids)[0]\n",
    "print(f\"Reading: {notes}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week7day1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
